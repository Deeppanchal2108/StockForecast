{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a360c2-a10d-4fde-b46d-fed001cf0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1af634-6d3d-4d97-ae8a-3f9b48a70e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for AAPL already exists. Skipping training...\n",
      "\n",
      "Model for GOOGL already exists. Skipping training...\n",
      "\n",
      "Model for MSFT already exists. Skipping training...\n",
      "\n",
      "Model for TSLA already exists. Skipping training...\n",
      "\n",
      "Model for AMZN already exists. Skipping training...\n",
      "\n",
      "Model for NFLX already exists. Skipping training...\n",
      "\n",
      "Model for META already exists. Skipping training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of stock tickers to train models on\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\", \"AMZN\", \"NFLX\", \"META\"]\n",
    "\n",
    "# Folder to store models and scalers\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    model_path = f\"models/{ticker}_lstm.h5\"\n",
    "    scaler_path = f\"models/{ticker}_scaler.pkl\"\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "        print(f\"Model for {ticker} already exists. Skipping training...\\n\")\n",
    "        continue  # Skip training if model already exists\n",
    "\n",
    "    print(f\"Training model for {ticker}...\")\n",
    "\n",
    "    # -------------------- Step 1: Download Data --------------------\n",
    "    start_date = \"2020-01-01\"\n",
    "    end_date = \"2024-12-31\"\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    # -------------------- Step 2: Preprocess Data --------------------\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df[\"Close_Scaled\"] = scaler.fit_transform(df[\"Close\"].values.reshape(-1, 1))\n",
    "\n",
    "    sequence_length = 60  # Use past 60 days to predict next day\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        X.append(df[\"Close_Scaled\"].iloc[i : i + sequence_length].values)\n",
    "        y.append(df[\"Close_Scaled\"].iloc[i + sequence_length])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # Reshape for LSTM\n",
    "\n",
    "    # -------------------- Step 3: Build LSTM Model --------------------\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=25),\n",
    "        Dense(units=1)  # Predicting 1 value (next day's price)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # -------------------- Step 4: Train Model --------------------\n",
    "    model.fit(X, y, batch_size=32, epochs=20, verbose=1)\n",
    "\n",
    "    # -------------------- Step 5: Save Model & Scaler --------------------\n",
    "    model.save(model_path)  # Save model\n",
    "    joblib.dump(scaler, scaler_path)  # Save scaler\n",
    "    print(f\"Model for {ticker} saved!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342b035f-6e5a-41ff-bce6-d901d9d5d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Predicted prices for AAPL over next 7 days: [239.1337738  239.2328186  238.99214172 238.53462219 237.93995667\n",
      " 237.25895691 236.52372742]\n"
     ]
    }
   ],
   "source": [
    "def predict_future_prices(ticker, days):\n",
    "    model_path = f\"models/{ticker}_lstm.h5\"\n",
    "    scaler_path = f\"models/{ticker}_scaler.pkl\"\n",
    "    \n",
    "    if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "        print(f\"Model or scaler missing for {ticker}. Exiting...\")\n",
    "        return None\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Fetch latest stock data\n",
    "    df = yf.download(ticker, period=\"70d\")\n",
    "    if df.shape[0] < 60:\n",
    "        print(f\"Not enough data to predict for {ticker}. Exiting...\")\n",
    "        return None\n",
    "    \n",
    "    last_60_days = df[\"Close\"].values[-60:].reshape(-1, 1)\n",
    "    last_60_days_scaled = scaler.transform(last_60_days)\n",
    "    \n",
    "    predictions = []\n",
    "    input_seq = last_60_days_scaled.copy()\n",
    "    \n",
    "    for _ in range(days):\n",
    "        X_test = np.array([input_seq])\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        \n",
    "        predicted_price_scaled = model.predict(X_test)\n",
    "        predicted_price = scaler.inverse_transform(predicted_price_scaled)[0][0]\n",
    "        predictions.append(predicted_price)\n",
    "        \n",
    "        # Update input sequence for next prediction\n",
    "        input_seq = np.append(input_seq[1:], predicted_price_scaled, axis=0)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "days = 7\n",
    "predicted_prices = predict_future_prices(ticker, days)\n",
    "if predicted_prices:\n",
    "    print(f\"Predicted prices for {ticker} over next {days} days: {np.array(predicted_prices).astype(float)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
